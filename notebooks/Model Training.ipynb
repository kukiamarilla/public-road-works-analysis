{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ba3346",
   "metadata": {},
   "source": [
    "# Flujo de entrenamiento (con precálculo / cache de embeddings por chunk)\n",
    "\n",
    "Este notebook implementa el flujo **2-etapas**:\n",
    "\n",
    "1) **Precalcular embeddings**: `texto licitación -> chunking -> ModeloB (GPT-OSS congelado) -> embeddings por chunk` y guardar en disco (`cache_dir/xxx.pt`)\n",
    "\n",
    "2) **Entrenar ModeloC** (cross-chunk + MLP) leyendo solo embeddings cacheados (rápido)\n",
    "\n",
    "3) **Inferencia**: `texto -> ModeloB -> embeddings -> ModeloC -> y_hat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06eca908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (4.57.3)\n",
      "Requirement already satisfied: accelerate in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (1.12.0)\n",
      "Requirement already satisfied: pandas in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: filelock in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from transformers) (3.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from transformers) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: psutil in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from accelerate) (7.2.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages (from requests->transformers) (2025.11.12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requisitos\n",
    "!pip install -U transformers accelerate pandas\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86b3e8",
   "metadata": {},
   "source": [
    "## Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c90390e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CFG(model_id='openai/gpt-oss-20b', device='cpu', dtype=torch.float32, max_len=4096, stride=2048, d_model=512, n_heads=8, ffn_dim=2048, dropout=0.1, batch_size=8, lr=0.0002, epochs=20, cache_dir='../data/chunk_embeddings')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    model_id: str = \"openai/gpt-oss-20b\"\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype: torch.dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "    # Chunking\n",
    "    max_len: int = 4096\n",
    "    stride: int = 2048\n",
    "\n",
    "    # Cross-chunk (liviano)\n",
    "    d_model: int = 512\n",
    "    n_heads: int = 8\n",
    "    ffn_dim: int = 2048\n",
    "    dropout: float = 0.1\n",
    "\n",
    "    # Training\n",
    "    batch_size: int = 8\n",
    "    lr: float = 2e-4\n",
    "    epochs: int = 20\n",
    "\n",
    "    # Cache\n",
    "    cache_dir: str = \"../data/chunk_embeddings\"\n",
    "\n",
    "cfg = CFG()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a35ce7b",
   "metadata": {},
   "source": [
    "## ModeloB – GPT-OSS congelado (embeddings por chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42dcaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelB_ChunkEmbedder(nn.Module):\n",
    "    def __init__(self, gpt_model, tokenizer, max_len=4096, stride=2048, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.gpt = gpt_model.eval()\n",
    "        for p in self.gpt.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.stride = stride\n",
    "        self.device = device\n",
    "\n",
    "        if self.tokenizer.pad_token_id is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.pad_id = self.tokenizer.pad_token_id\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, text: str) -> torch.Tensor:\n",
    "        enc = self.tokenizer(text, return_tensors=\"pt\", truncation=False)\n",
    "        input_ids = enc[\"input_ids\"][0].to(self.device)\n",
    "        attn_mask = enc[\"attention_mask\"][0].to(self.device)\n",
    "        L = int(attn_mask.sum().item())\n",
    "\n",
    "        chunk_embs = []\n",
    "        \n",
    "        for start in range(0, max(1, L), self.stride):\n",
    "            end = min(start + self.max_len, L)\n",
    "            ids = input_ids[start:end]\n",
    "            am  = attn_mask[start:end]\n",
    "            if ids.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            pad_len = self.max_len - ids.numel()\n",
    "            if pad_len > 0:\n",
    "                ids = torch.cat([ids, torch.full((pad_len,), self.pad_id, device=self.device, dtype=ids.dtype)])\n",
    "                am  = torch.cat([am, torch.zeros((pad_len,), device=self.device, dtype=am.dtype)])\n",
    "\n",
    "            # Procesar UN chunk a la vez (no batching)\n",
    "            out = self.gpt(input_ids=ids.unsqueeze(0), attention_mask=am.unsqueeze(0), return_dict=True)\n",
    "            h = out.last_hidden_state  # [1,T,d]\n",
    "            \n",
    "            last_idx = int(am.sum().item()) - 1\n",
    "            chunk_embs.append(h[0, last_idx].clone())  # [d]\n",
    "            \n",
    "            # Liberar memoria\n",
    "            del out, h\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            if end == L:\n",
    "                break\n",
    "\n",
    "        return torch.stack(chunk_embs)  # [N,d]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de6414",
   "metadata": {},
   "source": [
    "## ModeloC – Cross-chunk (no causal) + MLP regressor (liviano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7567115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelC_CrossChunkRegressor(nn.Module):\n",
    "    def __init__(self, d_in: int, d_model: int = 512, n_heads: int = 8, ffn_dim: int = 2048, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_in, d_model)\n",
    "\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=ffn_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "            activation=\"gelu\",\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(layer, num_layers=1)\n",
    "\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, chunk_embs: torch.Tensor, valid_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        B, N, _ = chunk_embs.shape\n",
    "        x = self.proj(chunk_embs)\n",
    "\n",
    "        cls = self.cls.expand(B, 1, -1)\n",
    "        x = torch.cat([cls, x], dim=1)\n",
    "\n",
    "        if valid_mask is not None:\n",
    "            cls_valid = torch.ones((B, 1), device=x.device, dtype=torch.bool)\n",
    "            valid = torch.cat([cls_valid, valid_mask], dim=1)\n",
    "            pad_mask = ~valid\n",
    "        else:\n",
    "            pad_mask = None\n",
    "\n",
    "        x = self.encoder(x, src_key_padding_mask=pad_mask)\n",
    "        pooled = x[:, 0]\n",
    "        return self.head(pooled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe936579",
   "metadata": {},
   "source": [
    "## Cargar datos (placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0e9e199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, torch.Size([244]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reemplazá esto por tu loader real (CSV/DB/paths/etc.)\n",
    "from pydoc import text\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/dataset.csv\")\n",
    "\n",
    "ids = list(df[\"Id llamado\"])\n",
    "texts = []\n",
    "for id in ids[:50]:\n",
    "    f = open(f\"../data/pbcs_extracted/{id}.txt\")\n",
    "    texts.append(f.read())\n",
    "targets = torch.tensor(list(df[\"Cantidad de oferentes\"]))\n",
    "len(texts), targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f2d192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d70179",
   "metadata": {},
   "source": [
    "## Inicializar GPT-OSS congelado + ModeloC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8347e1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kukiamarilla/Proyectos/tesis/public-road-works-analysis/venv/lib/python3.13/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2880"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(cfg.model_id)\n",
    "# base = AutoModel.from_pretrained(cfg.model_id, dtype=cfg.dtype).to(cfg.device)\n",
    "\n",
    "# modelB = ModelB_ChunkEmbedder(base, tokenizer, max_len=cfg.max_len, stride=cfg.stride, device=cfg.device)\n",
    "\n",
    "# d_in = base.config.hidden_size\n",
    "d_in = 2880\n",
    "modelC = ModelC_CrossChunkRegressor(d_in=d_in, d_model=cfg.d_model, n_heads=cfg.n_heads, ffn_dim=cfg.ffn_dim, dropout=cfg.dropout).to(cfg.device)\n",
    "d_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf86a78",
   "metadata": {},
   "source": [
    "## (1) Precálculo / cache de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ede07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db5948351854f298eef6b0b3ee64f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cacheando embeddings:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache listo: ./cache_chunk_embs\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def precache_embeddings(texts: List[str], targets: torch.Tensor, tender_ids: List, modelB: ModelB_ChunkEmbedder, cache_dir: str):\n",
    "    \"\"\"\n",
    "    Genera embeddings y los guarda con el ID de licitación como nombre de archivo.\n",
    "    Args:\n",
    "        texts: Lista de textos de licitaciones\n",
    "        targets: Tensor con cantidad de oferentes\n",
    "        tender_ids: Lista de IDs de licitación (mismo orden que texts)\n",
    "        modelB: Modelo para generar embeddings\n",
    "        cache_dir: Directorio donde guardar los .pt\n",
    "    \"\"\"\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    for tender_id, txt, y in tqdm(zip(tender_ids, texts, targets), total=len(texts), desc=\"Cacheando embeddings\"):\n",
    "        path = os.path.join(cache_dir, f\"{tender_id}.pt\")\n",
    "        if os.path.exists(path):\n",
    "            continue\n",
    "\n",
    "        embs = modelB(txt).cpu()  # [N,d]\n",
    "        torch.save({\"embs\": embs, \"y\": float(y.item()), \"tender_id\": tender_id}, path)\n",
    "\n",
    "    print(\"cache listo:\", cache_dir)\n",
    "\n",
    "# Pasar los IDs de licitación como tercer argumento\n",
    "precache_embeddings(texts, targets, ids[:50], modelB, cfg.cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d29a98",
   "metadata": {},
   "source": [
    "## (2) Dataset cacheado + collate (padding por N chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f443207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 49 | Train: 39 | Val: 10\n",
      "Train batches: 5 | Val batches: 2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "class CachedChunkEmbDataset(Dataset):\n",
    "    def __init__(self, cache_dir: str):\n",
    "        self.files = sorted([os.path.join(cache_dir, f) for f in os.listdir(cache_dir) if f.endswith(\".pt\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        d = torch.load(self.files[idx], map_location=\"cpu\")\n",
    "        return d[\"embs\"].float(), torch.tensor(d[\"y\"], dtype=torch.float32)\n",
    "\n",
    "def collate_pad_chunks(batch: List[Tuple[torch.Tensor, torch.Tensor]]):\n",
    "    embs_list, y_list = zip(*batch)\n",
    "    B = len(embs_list)\n",
    "    d = embs_list[0].shape[1]\n",
    "    Nmax = max(e.shape[0] for e in embs_list)\n",
    "\n",
    "    embs = torch.zeros((B, Nmax, d), dtype=torch.float32)\n",
    "    valid = torch.zeros((B, Nmax), dtype=torch.bool)\n",
    "\n",
    "    for i, e in enumerate(embs_list):\n",
    "        n = e.shape[0]\n",
    "        embs[i, :n] = e\n",
    "        valid[i, :n] = True\n",
    "\n",
    "    y = torch.stack(y_list).view(B, 1)\n",
    "    return embs, valid, y\n",
    "\n",
    "# Crear dataset completo\n",
    "ds = CachedChunkEmbDataset(cfg.cache_dir)\n",
    "\n",
    "# Split 80% train / 20% val\n",
    "train_size = int(0.8 * len(ds))\n",
    "val_size = len(ds) - train_size\n",
    "train_ds, val_ds = random_split(ds, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dl = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, collate_fn=collate_pad_chunks)\n",
    "val_dl = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=collate_pad_chunks)\n",
    "\n",
    "print(f\"Total: {len(ds)} | Train: {len(train_ds)} | Val: {len(val_ds)}\")\n",
    "print(f\"Train batches: {len(train_dl)} | Val batches: {len(val_dl)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e6477",
   "metadata": {},
   "source": [
    "## (3) Entrenamiento de ModeloC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c0277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | loss=1.6575\n",
      "epoch 02 | loss=1.3344\n",
      "epoch 03 | loss=1.4606\n",
      "epoch 04 | loss=1.3023\n",
      "epoch 05 | loss=1.3574\n",
      "epoch 06 | loss=1.3579\n",
      "epoch 07 | loss=1.2449\n",
      "epoch 08 | loss=1.5998\n",
      "epoch 09 | loss=1.1260\n",
      "epoch 10 | loss=1.0303\n"
     ]
    }
   ],
   "source": [
    "def train_modelC(modelC: nn.Module, train_dl: DataLoader, val_dl: DataLoader, cfg: CFG):\n",
    "    opt = torch.optim.AdamW(modelC.parameters(), lr=cfg.lr, weight_decay=0.01)\n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "    \n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "\n",
    "    for ep in range(1, cfg.epochs + 1):\n",
    "        # --- Training ---\n",
    "        modelC.train()\n",
    "        train_total = 0.0\n",
    "        for embs, valid, y in train_dl:\n",
    "            embs = embs.to(cfg.device)\n",
    "            valid = valid.to(cfg.device)\n",
    "            y = y.to(cfg.device)\n",
    "\n",
    "            y_hat = modelC(embs, valid)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            train_total += float(loss.item())\n",
    "        \n",
    "        train_loss = train_total / len(train_dl)\n",
    "        \n",
    "        # --- Validation ---\n",
    "        modelC.eval()\n",
    "        val_total = 0.0\n",
    "        with torch.no_grad():\n",
    "            for embs, valid, y in val_dl:\n",
    "                embs = embs.to(cfg.device)\n",
    "                valid = valid.to(cfg.device)\n",
    "                y = y.to(cfg.device)\n",
    "\n",
    "                y_hat = modelC(embs, valid)\n",
    "                loss = loss_fn(y_hat, y)\n",
    "                val_total += float(loss.item())\n",
    "        \n",
    "        val_loss = val_total / len(val_dl)\n",
    "        \n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        \n",
    "        print(f\"epoch {ep:02d} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "history = train_modelC(modelC, train_dl, val_dl, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c096c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "plt.plot(epochs, history[\"train_loss\"], 'b-o', label='Train Loss', linewidth=2, markersize=6)\n",
    "plt.plot(epochs, history[\"val_loss\"], 'r-s', label='Validation Loss', linewidth=2, markersize=6)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss (SmoothL1)', fontsize=12)\n",
    "plt.title('Training vs Validation Loss', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(epochs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20355dd2",
   "metadata": {},
   "source": [
    "## Guardar pesos de ModeloC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c04dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoints/modelC_crosschunk.pt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"./checkpoints\", exist_ok=True)\n",
    "ckpt_path = \"./checkpoints/modelC_crosschunk.pt\"\n",
    "torch.save(modelC.state_dict(), ckpt_path)\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae40f9",
   "metadata": {},
   "source": [
    "## (4) Inferencia final (ModeloA = B + C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a29875f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4982], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ModelA_Full(nn.Module):\n",
    "    def __init__(self, modelB: ModelB_ChunkEmbedder, modelC: nn.Module):\n",
    "        super().__init__()\n",
    "        self.B = modelB\n",
    "        self.C = modelC\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_one(self, text: str) -> torch.Tensor:\n",
    "        chunk_vecs = self.B(text)              # [N,d] - bfloat16\n",
    "        chunk_vecs = chunk_vecs.float()        # Convertir a float32\n",
    "        chunk_vecs = chunk_vecs.unsqueeze(0)   # [1,N,d]\n",
    "        valid = torch.ones((1, chunk_vecs.size(1)), device=chunk_vecs.device, dtype=torch.bool)\n",
    "        self.C.eval()\n",
    "        y_hat = self.C(chunk_vecs, valid)      # [1,1]\n",
    "        return y_hat.squeeze(0)\n",
    "\n",
    "modelA = ModelA_Full(modelB, modelC)\n",
    "\n",
    "f = open(\"341016.txt\", \"r\")\n",
    "test_text = f.read()\n",
    "pred = modelA.predict_one(test_text)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2391e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
